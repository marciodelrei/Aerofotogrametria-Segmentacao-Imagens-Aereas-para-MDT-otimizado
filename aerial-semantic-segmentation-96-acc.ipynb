{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. import the necessery libraries\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras import regularizers\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:04.36231Z","iopub.execute_input":"2022-09-18T18:08:04.362621Z","iopub.status.idle":"2022-09-18T18:08:04.371351Z","shell.execute_reply.started":"2022-09-18T18:08:04.362587Z","shell.execute_reply":"2022-09-18T18:08:04.369764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. load and split the data ","metadata":{}},{"cell_type":"code","source":"import os \nimport numpy as np \nimport pandas as pd \nimport imageio \nimport matplotlib.pyplot as plt \n%matplotlib inline \n\npath =''\nimage_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/')\nmask_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/')\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]\nimage_list = sorted(image_list)\nmask_list = sorted(mask_list)\ntrain_image_list = image_list[:390]\ntrain_mask_list = mask_list[:390]\n\nvalidation_image_list = image_list[390:400]\nvalidation_mask_list = mask_list[390:400]\n\nprint(\"number of train images is : {} \".format(len(train_image_list)))\nprint(\"number of train masks is : {} \".format(len(train_mask_list)))\n\nprint(\"number of train images is : {} \".format(len(validation_image_list)))\nprint(\"number of train masks is : {} \".format(len(validation_mask_list)))\n\nprint(image_list[0])\nprint(mask_list[0])","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:04.374143Z","iopub.execute_input":"2022-09-18T18:08:04.375217Z","iopub.status.idle":"2022-09-18T18:08:04.411861Z","shell.execute_reply.started":"2022-09-18T18:08:04.375154Z","shell.execute_reply":"2022-09-18T18:08:04.410416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. explore some images :","metadata":{}},{"cell_type":"code","source":"n = 10 # you can chose any index \nimg  = imageio.imread(train_image_list[n])\nprint(img.shape)\nmask = imageio.imread(train_mask_list[n])\nprint(mask.shape)\n\n# now let's plot \nfig ,arr  = plt.subplots(1,2,figsize=(15,10))\narr[0].imshow(img)\narr[0].set_title('Original Image')\narr[1].imshow(mask)\narr[1].set_title('Mask')","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:04.413639Z","iopub.execute_input":"2022-09-18T18:08:04.41488Z","iopub.status.idle":"2022-09-18T18:08:11.280226Z","shell.execute_reply.started":"2022-09-18T18:08:04.414815Z","shell.execute_reply":"2022-09-18T18:08:11.278914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"train_images = tf.constant(train_image_list)\ntrain_masks = tf.constant(train_mask_list)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_masks))\nfor image,mask in train_dataset.take(1) : \n    print(image)\n    print(mask)\n    \nvalidation_images = tf.constant(validation_image_list)\nvalidation_masks = tf.constant(validation_mask_list)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((validation_images,validation_masks))\nfor image,mask in validation_dataset.take(1) : \n    print(image)\n    print(mask)    ","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.283391Z","iopub.execute_input":"2022-09-18T18:08:11.28378Z","iopub.status.idle":"2022-09-18T18:08:11.357478Z","shell.execute_reply.started":"2022-09-18T18:08:11.283705Z","shell.execute_reply":"2022-09-18T18:08:11.356188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. preprocessing our data","metadata":{}},{"cell_type":"code","source":"def process_path(image_path,mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img,channels=3)\n    img = tf.image.convert_image_dtype(img,tf.float32) #this do the same as dividing by 255 to set the values between 0 and 1 (normalization)\n    \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask,channels=3)\n    mask = tf.math.reduce_max(mask,axis=-1,keepdims=True)\n    return img , mask\n\ndef preprocess(image,mask) : \n    input_image = tf.image.resize(image,(96,128),method='nearest')\n    input_mask = tf.image.resize(mask,(96,128),method='nearest')\n    \n    return input_image , input_mask\n\ntrain_image_ds = train_dataset.map(process_path) # apply the preprocces_path function to our train_dataset\nprint(image_ds)\ntrain_processed_image_ds = train_image_ds.map(preprocess) # apply the preprocess function to our train_dataset\n\nvalidation_image_ds = validation_dataset.map(process_path) # apply the preprocces_path function to our validation_dataset\nprint(image_ds)\nvalidation_processed_image_ds = validation_image_ds.map(preprocess) \n","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.359132Z","iopub.execute_input":"2022-09-18T18:08:11.366919Z","iopub.status.idle":"2022-09-18T18:08:11.471851Z","shell.execute_reply.started":"2022-09-18T18:08:11.366866Z","shell.execute_reply":"2022-09-18T18:08:11.470791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.  Define The Conv Block For The Contracting Path\n","metadata":{}},{"cell_type":"code","source":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \n    conv = Conv2D(n_filters, \n                  kernel_size = 3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n    conv = Conv2D(n_filters, \n                  kernel_size = 3, \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n   \n    \n\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n        \n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n        \n        \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.474224Z","iopub.execute_input":"2022-09-18T18:08:11.475024Z","iopub.status.idle":"2022-09-18T18:08:11.485809Z","shell.execute_reply.started":"2022-09-18T18:08:11.474976Z","shell.execute_reply":"2022-09-18T18:08:11.484433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Define the upsampling block for the expanding path","metadata":{}},{"cell_type":"code","source":"def upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \n    up = Conv2DTranspose(\n                 n_filters,  \n                 kernel_size = 3,\n                 strides=(2,2),\n                 padding='same')(expansive_input)\n    \n    merge = concatenate([up, contractive_input], axis=3)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,   \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,  \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n    \n    \n    return conv","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.488875Z","iopub.execute_input":"2022-09-18T18:08:11.490147Z","iopub.status.idle":"2022-09-18T18:08:11.501157Z","shell.execute_reply.started":"2022-09-18T18:08:11.490092Z","shell.execute_reply":"2022-09-18T18:08:11.499914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Finally! ,  we will Define the unet model \n## which composes of a set of conv blocks and upsampling blocks","metadata":{}},{"cell_type":"code","source":"def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n    \n    inputs = Input(input_size)\n    \n    # contracting path\n    cblock1 = conv_block(inputs, n_filters, dropout_prob=0.4)\n    cblock2 = conv_block(cblock1[0], 2*n_filters, dropout_prob=0.4)\n    cblock3 = conv_block(cblock2[0], 4*n_filters, dropout_prob=0.4)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.45) \n    cblock5 = conv_block(cblock4[0],16*n_filters, dropout_prob=0.4, max_pooling=None)     \n    \n    # expanding path\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n    \n    conv10 = Conv2D(n_classes, kernel_size=1, padding='same')(conv9)  \n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.504041Z","iopub.execute_input":"2022-09-18T18:08:11.504913Z","iopub.status.idle":"2022-09-18T18:08:11.521228Z","shell.execute_reply.started":"2022-09-18T18:08:11.504863Z","shell.execute_reply":"2022-09-18T18:08:11.519956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 96\nimg_width = 128\nnum_channels = 3\n\nunet = unet_model((img_height, img_width, num_channels))","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.526575Z","iopub.execute_input":"2022-09-18T18:08:11.528Z","iopub.status.idle":"2022-09-18T18:08:11.816061Z","shell.execute_reply.started":"2022-09-18T18:08:11.527758Z","shell.execute_reply":"2022-09-18T18:08:11.813567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Our model is ready !!","metadata":{}},{"cell_type":"code","source":"unet.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.819508Z","iopub.execute_input":"2022-09-18T18:08:11.820517Z","iopub.status.idle":"2022-09-18T18:08:11.870803Z","shell.execute_reply.started":"2022-09-18T18:08:11.82047Z","shell.execute_reply":"2022-09-18T18:08:11.869755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.873569Z","iopub.execute_input":"2022-09-18T18:08:11.873979Z","iopub.status.idle":"2022-09-18T18:08:11.907132Z","shell.execute_reply.started":"2022-09-18T18:08:11.873913Z","shell.execute_reply":"2022-09-18T18:08:11.90595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 500\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 390\nBATCH_SIZE = 16\n\n# train\ntrain_processed_image_ds.batch(BATCH_SIZE)\ntrain_dataset = train_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(train_processed_image_ds.element_spec)\n\n# validation\nvalidation_processed_image_ds.batch(BATCH_SIZE)\nvalidation_dataset = validation_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(validation_processed_image_ds.element_spec)\n \n\nmodel_history = unet.fit(train_dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:08:11.912256Z","iopub.execute_input":"2022-09-18T18:08:11.915773Z","iopub.status.idle":"2022-09-18T18:23:35.878306Z","shell.execute_reply.started":"2022-09-18T18:08:11.915697Z","shell.execute_reply":"2022-09-18T18:23:35.877125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:35.880756Z","iopub.execute_input":"2022-09-18T18:23:35.881614Z","iopub.status.idle":"2022-09-18T18:23:36.136361Z","shell.execute_reply.started":"2022-09-18T18:23:35.881564Z","shell.execute_reply":"2022-09-18T18:23:36.135325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:36.13848Z","iopub.execute_input":"2022-09-18T18:23:36.139117Z","iopub.status.idle":"2022-09-18T18:23:36.147981Z","shell.execute_reply.started":"2022-09-18T18:23:36.139057Z","shell.execute_reply":"2022-09-18T18:23:36.146904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:36.150123Z","iopub.execute_input":"2022-09-18T18:23:36.15082Z","iopub.status.idle":"2022-09-18T18:23:36.162367Z","shell.execute_reply.started":"2022-09-18T18:23:36.150655Z","shell.execute_reply":"2022-09-18T18:23:36.1609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predictions(dataset=None, num=1):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = unet.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:36.164302Z","iopub.execute_input":"2022-09-18T18:23:36.164635Z","iopub.status.idle":"2022-09-18T18:23:36.175164Z","shell.execute_reply.started":"2022-09-18T18:23:36.164604Z","shell.execute_reply":"2022-09-18T18:23:36.173709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"----- training_dataset results---------\")\nshow_predictions(train_dataset, 6)\nprint(\"----- validation_dataset results---------\")\nshow_predictions(validation_dataset, 6)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:36.177061Z","iopub.execute_input":"2022-09-18T18:23:36.177509Z","iopub.status.idle":"2022-09-18T18:23:51.557445Z","shell.execute_reply.started":"2022-09-18T18:23:36.17748Z","shell.execute_reply":"2022-09-18T18:23:51.556267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model evaluation\nprint(\"Unet Model Evaluation: \")\nunet.evaluate(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T18:23:51.560741Z","iopub.execute_input":"2022-09-18T18:23:51.561654Z","iopub.status.idle":"2022-09-18T18:23:52.474341Z","shell.execute_reply.started":"2022-09-18T18:23:51.561591Z","shell.execute_reply":"2022-09-18T18:23:52.473181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TODO\n\n* [ x ] Modelo Checkpoint\n* [ ] Mostrar previsão de validação durante o treinamento\n* [ ] Criar os gráficos val_acc e val_loss\n* [ ] Mostrar o gráfico de acurácia durante o treinamento","metadata":{}},{"cell_type":"markdown","source":"# 1. import the necessery libraries\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pickle\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras import regularizers\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DateTimeStamp para taggear arquivos e gerar \"versionamento\" para evitar sobrescritas\n\nfrom datetime import datetime\nfmtedDateTime = datetime.now().strftime('%Y%m%d%H%M%S')\nprint(fmtedDateTime)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. load and split the data ","metadata":{}},{"cell_type":"code","source":"import os \nimport numpy as np \nimport pandas as pd \nimport imageio \nimport matplotlib.pyplot as plt \n%matplotlib inline \n\npath =''\nimage_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/')\nmask_path = os.path.join(path,'../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/')\nimage_list = sorted(os.listdir(image_path))\nmask_list = sorted(os.listdir(mask_path))\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]\nimage_list = sorted(image_list)\nmask_list = sorted(mask_list)\ntrain_image_list = image_list[:390]\ntrain_mask_list = mask_list[:390]\n\nvalidation_image_list = image_list[390:400]\nvalidation_mask_list = mask_list[390:400]\n\nprint(\"number of train images is : {} \".format(len(train_image_list)))\nprint(\"number of train masks is : {} \".format(len(train_mask_list)))\n\nprint(\"number of train images is : {} \".format(len(validation_image_list)))\nprint(\"number of train masks is : {} \".format(len(validation_mask_list)))\n\nprint(image_list[0])\nprint(mask_list[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of samples:\", len(image_list))\n\nfor input_path, target_path in zip(image_list[:10], mask_list[:10]):\n    print(input_path, \"|\", target_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. explore some images :","metadata":{}},{"cell_type":"code","source":"n = 10 # you can chose any index \nimg  = imageio.imread(train_image_list[n])\nprint(img.shape)\nmask = imageio.imread(train_mask_list[n])\nprint(mask.shape)\n\n# now let's plot \nfig ,arr  = plt.subplots(1,2,figsize=(15,10))\narr[0].imshow(img)\narr[0].set_title('Original Image')\narr[1].imshow(mask)\narr[1].set_title('Mask')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"train_images = tf.constant(train_image_list)\ntrain_masks = tf.constant(train_mask_list)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_masks))\nfor image,mask in train_dataset.take(1) : \n    print(image)\n    print(mask)\n    \nvalidation_images = tf.constant(validation_image_list)\nvalidation_masks = tf.constant(validation_mask_list)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((validation_images,validation_masks))\nfor image,mask in validation_dataset.take(1) : \n    print(image)\n    print(mask)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. preprocessing our data","metadata":{}},{"cell_type":"code","source":"def process_path(image_path,mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img,channels=3)\n    img = tf.image.convert_image_dtype(img,tf.float32) #this do the same as dividing by 255 to set the values between 0 and 1 (normalization)\n    \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask,channels=3)\n    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    return img , mask\n\ndef preprocess(image,mask) : \n    input_image = tf.image.resize(image,(96,128),method='nearest')\n    input_mask = tf.image.resize(mask,(96,128),method='nearest')\n    \n    return input_image , input_mask\n\ntrain_image_ds = train_dataset.map(process_path) # apply the preprocces_path function to our train_dataset\nprint(train_image_ds)\ntrain_processed_image_ds = train_image_ds.map(preprocess) # apply the preprocess function to our train_dataset\n\nvalidation_image_ds = validation_dataset.map(process_path) # apply the preprocces_path function to our validation_dataset\nprint(validation_image_ds)\nvalidation_processed_image_ds = validation_image_ds.map(preprocess) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.  Define The Conv Block For The Contracting Path\n","metadata":{}},{"cell_type":"code","source":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \n    conv = Conv2D(n_filters, \n                  kernel_size = 3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n\n    conv = Conv2D(n_filters, \n                  kernel_size = 3, \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n        \n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n\n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Define the upsampling block for the expanding path","metadata":{}},{"cell_type":"code","source":"def upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \n    up = Conv2DTranspose(\n                 n_filters,  \n                 kernel_size = 3,\n                 strides=(2,2),\n                 padding='same')(expansive_input)\n    \n    merge = concatenate([up, contractive_input], axis=3)\n    \n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,   \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n    \n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,  \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n    \n    return conv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Finally! ,  we will Define the unet model \n## which composes of a set of conv blocks and upsampling blocks","metadata":{}},{"cell_type":"code","source":"def build_unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n    \n    inputs = Input(input_size)\n    \n    # contracting path\n    cblock1 = conv_block(inputs, n_filters, dropout_prob=0.4)\n    cblock2 = conv_block(cblock1[0], 2*n_filters, dropout_prob=0.4)\n    cblock3 = conv_block(cblock2[0], 4*n_filters, dropout_prob=0.4)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.45) \n    cblock5 = conv_block(cblock4[0],16*n_filters, dropout_prob=0.4, max_pooling=None)     \n    \n    # expanding path\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n    \n    conv10 = Conv2D(n_classes, kernel_size=1, padding='same')(conv9)  \n    model = tf.keras.Model(inputs=inputs, outputs=conv10, name=f\"{fmtedDateTime}_U-Net\")\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 96\nimg_width = 128\nnum_channels = 3\n\nunet = build_unet_model((img_height, img_width, num_channels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import array_to_img\n\ndef display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]\n\ndef show_predictions(dataset=None, num=1):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = unet.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n\n    else:\n        display([sample_image, sample_mask,\n             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Our model is ready !!","metadata":{}},{"cell_type":"code","source":"unet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Incluindo alguns Callbacks e provas visuais de acurácia\nFontes de estudo:\n\n**Callbacks e \nModelCheckPoint**\n\n* Aulas BI_Master\n* https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n* https://pyimagesearch.com/2021/06/30/how-to-use-the-modelcheckpoint-callback-with-keras-and-tensorflow/\n","metadata":{}},{"cell_type":"markdown","source":"Criando Checkpoint","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Salvando apenas os pesos, logo, para se utilizar o modelo posteriormente,\n# será preciso reconstruí-lo e carregar os pesos\ncheckpoint_filepath = f\"/kaggle/working/{fmtedDateTime}_bestModelWeigths.h5\"\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\nearly_stop = EarlyStopping(monitor='val_accuracy', patience=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Criando callback de visualização parcial das inferências durante o treino","metadata":{}},{"cell_type":"code","source":"def display_learning_curves(history):\n    history = history\n    acc = history.history[\"accuracy\"]\n    val_acc = history.history[\"val_accuracy\"]\n\n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n\n#     epochs_range = range(NUM_EPOCHS)\n\n    fig = plt.figure(figsize=(30, 5))\n\n    # summarize history for accuracy\n    plt.subplot(1,2,1)\n    plt.plot(acc, label=\"train accuracy\")\n    plt.plot(val_acc, label=\"validataion accuracy\")\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n#     plt.show()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(loss, label=\"train loss\")\n    plt.plot(val_loss, label=\"validataion loss\")\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n#     plt.subplot(1,2,1)\n#     plt.plot(epochs_range, acc, label=\"train accuracy\")\n#     plt.plot(epochs_range, val_acc, label=\"validataion accuracy\")\n#     plt.title(\"Accuracy\")\n#     plt.xlabel(\"Epoch\")\n#     plt.ylabel(\"Accuracy\")\n#     plt.legend(loc=\"lower right\")\n\n#     plt.subplot(1,2,2)\n#     plt.plot(epochs_range, loss, label=\"train loss\")\n#     plt.plot(epochs_range, val_loss, label=\"validataion loss\")\n#     plt.title(\"Loss\")\n#     plt.xlabel(\"Epoch\")\n#     plt.ylabel(\"Loss\")\n#     plt.legend(loc=\"upper right\")\n\n    fig.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\n\nclass DisplayCallback(Callback):\n    def __init__(self, model):\n        self.model = model\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % 10 == 0:\n            print(\"--------- partial results ---------\")\n            display_learning_curves(self.model.history)\n            print(\"------- partial predictions -------\")\n            show_predictions(train_dataset, 1)            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import inspect\n\ninspect.getfullargspec(unet.fit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1000\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 390\nBATCH_SIZE = 64\n\n# train\ntrain_processed_image_ds.batch(BATCH_SIZE)\ntrain_dataset = train_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n# print(train_processed_image_ds.element_spec)\n\n# validation\nvalidation_processed_image_ds.batch(BATCH_SIZE)\nvalidation_dataset = validation_processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n# print(validation_processed_image_ds.element_spec)\n \n# callbacks_list = [model_checkpoint_callback, early_stop, DisplayCallback()]\ncallbacks_list = [DisplayCallback(unet), early_stop, model_checkpoint_callback]\nmodel_history = unet.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=EPOCHS,\n    callbacks=callbacks_list,\n    verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Salvando o Model History caso seja necessário buscar métricas no futuro","metadata":{}},{"cell_type":"code","source":"def save_history(history, dest_path):\n    with open(dest_path, \"wb\") as file_hist:\n        pickle.dump(history.history, file_hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_history(model_history, f\"/kaggle/working/{fmtedDateTime}_ModelHistory.pkl\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fmtedDateTime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Carregar o Model History","metadata":{}},{"cell_type":"code","source":"def load_history(history_path):\n    history = None\n    with open(history_path, \"rb\") as file_hist:\n        history = pickle.load(file_hist)\n        \n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = load_history(f\"/kaggle/working/{fmtedDateTime}_ModelHistry.pkl\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, key in enumerate(history):\n    print(idx, key)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model evaluation\nprint(\"Unet Model Evaluation: \")\nunet.evaluate(validation_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.load_weights(\"/kaggle/working/20230612183426_bestModelWeigths.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"----- training_dataset results---------\")\nshow_predictions(train_dataset, 6)\nprint(\"----- validation_dataset results---------\")\nshow_predictions(validation_dataset, 6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_predicted_mask(image, image_name):\n    predicted_mask_path = \"/kaggle/working/predicted_mask\"\n    if os.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reprocess(image,mask) : \n    input_image = tf.image.resize(image,(4000,6000),method='nearest')\n    input_mask = tf.image.resize(mask,(4000,6000),method='nearest')\n    \n    return input_image , input_mask","metadata":{},"execution_count":null,"outputs":[]}]}